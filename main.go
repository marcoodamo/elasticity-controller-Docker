package main

import (
        "context"
        "fmt"
        "log"
        "time"

        "github.com/docker/docker/api/types/container"
        "github.com/docker/docker/client"
        "github.com/prometheus/client_golang/api"
        v1 "github.com/prometheus/client_golang/api/prometheus/v1"
        "github.com/prometheus/common/model"
)

const (
        prometheusURL   = "http://localhost:9090"
        thresholdCPU    = 80.0
        thresholdMemUp  = 75.0
        thresholdMemDown= 40.0
        scaleUpFactor   = 1.2
        scaleDownFactor = 0.8
        containerName   = "nginx-monitored"
)

/*
Essa funÃ§Ã£o (fetchPrometheusMetrics) se conecta ao Prometheus para executar uma  
consulta e obter uma mÃ©trica. Faz isso criando o cliente Prometheus utilizando a URL configurada, 
executa a consulta ao endpoint com timeout de 10 seg, e retorna o valor obtido (ou erro)
*/

func fetchPrometheusMetrics(query string) (float64, error) {
        client, err := api.NewClient(api.Config{Address: prometheusURL})
        if err != nil {
                return 0, fmt.Errorf("erro ao criar cliente do Prometheus: %v", err)
        }

        v1api := v1.NewAPI(client)
        ctx, cancel := context.WithTimeout(context.Background(), 10*time.Second)
        defer cancel()

        result, _, err := v1api.Query(ctx, query, time.Now())
        if err != nil {
                return 0, fmt.Errorf("erro ao consultar o Prometheus: %v", err)
        }

        vectorVal, ok := result.(model.Vector)
        if !ok || len(vectorVal) == 0 {
                return 0, nil
        }

        return float64(vectorVal[0].Value), nil
}

/*
Esta funÃ§Ã£o consulta o uso da CPU do contÃªiner especificado, que no caso Ã© o nginx-monitored (containerName).
Para isso Ã© montada a query PromQL para obter a taxa de uso do contÃªiner nos Ãºltimos 15 seg, utilizando a
funÃ§Ã£o fetchPrometheusMetrics mostrada anteriormente. Depois calcula a porcentagem de uso em relaÃ§Ã£o ao limite
atual e retorna o valor
*/

func fetchCPUMetrics(containerName string, currentCPULimit float64) (float64, error) {
        query := fmt.Sprintf(`rate(container_cpu_usage_seconds_total{name="%s"}[15s])`, containerName)
        cpuUsage, err := fetchPrometheusMetrics(query)
        if err != nil {
                return 0, err
        }
        return (cpuUsage / currentCPULimit) * 100, nil
}

/*
Esta funÃ§Ã£o consulta a quantidade de memÃ³ria utilizada pelo contÃªiner, da mesma forma que Ã© feito o fetchCPUMetrics
*/

func fetchMemoryMetrics() (float64, error) {
        query := fmt.Sprintf(`container_memory_working_set_bytes{name="%s"}`, containerName)
        memUsage, err := fetchPrometheusMetrics(query)
        if err != nil {
                return 0, err
        }
        return memUsage / (1024 * 1024), nil // Converte p/ MB
}

/*
Atualiza os limites de CPU e memÃ³ria do contÃªiner, para isso cria um cliente Docker para interagir
com a API, define os novos valores de CPU e memÃ³ria, convertando a CPU para NanoCPU e a memÃ³ria
para bytes, depois chama "ContainerUpdate" pra aplicar as novas configs do contÃªiner e registra
os novos limites aplicados no log
*/

func updateContainerResources(containerID string, newCPULimit float64, newMemoryLimit int64) error {
        cli, err := client.NewClientWithOpts(client.FromEnv, client.WithAPIVersionNegotiation())
        if err != nil {
                return fmt.Errorf("erro ao criar cliente Docker: %v", err)
        }

        resources := container.Resources{
                NanoCPUs:   int64(newCPULimit * 1e9),
                Memory:     newMemoryLimit,
                MemorySwap: newMemoryLimit * 2,
        }

        updateConfig := container.UpdateConfig{Resources: resources}

        _, err = cli.ContainerUpdate(context.Background(), containerID, updateConfig)
        if err != nil {
                return fmt.Errorf("erro ao atualizar os recursos do contÃªiner: %v", err)
        }

        log.Printf("Novo limite aplicado: CPU = %.2f cores, MemÃ³ria = %.2f MB", newCPULimit, float64(newMemoryLimit)/(1024*1024))
        return nil
}

/*
Faz as verificaÃ§Ãµes para ajustar dinamicamente os recursos do conteiner com base na utilizaÃ§Ã£o atual
e caso necessÃ¡rio chama a funÃ§Ã£o updateContainerResources para atualizar os recursos. Como a mÃ¡quina 
*/

func adjustContainer(containerID string, cpuUsage float64, memUsage float64, currentCPULimit *float64, currentMemoryLimit *int64, initialMemoryLimit int64) error {
    newCPULimit := *currentCPULimit
    newMemoryLimit := *currentMemoryLimit

    if cpuUsage > thresholdCPU {
        newCPULimit *= scaleUpFactor
        // Como o host tem 4 vCPU, setei o limite como 4 para o cÃ³digo nÃ£o tentar ultrapassar os limites
        if newCPULimit > 4.0 {
            newCPULimit = 4.0
        }
        log.Printf("ðŸ”¼ Aumentando CPU para %.2f cores", newCPULimit)
    } else if cpuUsage < thresholdCPU*0.5 {
        newCPULimit *= scaleDownFactor
        // Valor definido no docker-compose, o quanto o container "nginx-monitored" deve ter de CPU
        if newCPULimit < 1.0 {
            newCPULimit = 1.0
        }
        log.Printf("ðŸ”½ Reduzindo CPU para %.2f cores", newCPULimit)
    }

    usagePercentage := (memUsage * 100) / float64(*currentMemoryLimit/(1024*1024))

    if usagePercentage > thresholdMemUp {
        newMemoryLimit = int64(float64(*currentMemoryLimit) * scaleUpFactor)
        // Host tem 8gb de ram
        if newMemoryLimit > (8 * 1024 * 1024 * 1024) {
            newMemoryLimit = 8 * 1024 * 1024 * 1024
        }
        log.Printf("ðŸ”¼ Aumentando memÃ³ria para %.2f MB", float64(newMemoryLimit)/(1024*1024))
    } else if usagePercentage < thresholdMemDown {
        newMemoryLimit = int64(float64(*currentMemoryLimit) * scaleDownFactor)
        // initialmemory = 512mb, definido na main (ainda vou arrumar para a CPU)
        if newMemoryLimit < initialMemoryLimit {
            newMemoryLimit = initialMemoryLimit
        }
        log.Printf("ðŸ”½ Reduzindo memÃ³ria para %.2f MB", float64(newMemoryLimit)/(1024*1024))
    }

    if newCPULimit != *currentCPULimit || newMemoryLimit != *currentMemoryLimit {
        err := updateContainerResources(containerID, newCPULimit, newMemoryLimit)
        if err != nil {
            return err
        }
        *currentCPULimit = newCPULimit
        *currentMemoryLimit = newMemoryLimit
    }

    log.Printf("ðŸ“Š Uso atual - CPU: %.2f%%, MemÃ³ria: %.2f MB (%.2f%% do limite)", cpuUsage, memUsage, usagePercentage)
    return nil
}

func main() {
    currentCPULimit := 1.0
    initialMemoryLimit := int64(512 * 1024 * 1024) // Armazena o valor inicial (512MB)
    currentMemoryLimit := initialMemoryLimit

    for {
        // Separar melhor os logs
        log.Println("=========================================")

        cpuUsage, err := fetchCPUMetrics(containerName, currentCPULimit)
        if err != nil {
            log.Printf("âŒ Erro ao buscar mÃ©tricas de CPU: %v", err)
            continue
        }

        memUsage, err := fetchMemoryMetrics()
        if err != nil {
            log.Printf("âŒ Erro ao buscar mÃ©tricas de memÃ³ria: %v", err)
            continue
        }

        err = adjustContainer(containerName, cpuUsage, memUsage, &currentCPULimit, &currentMemoryLimit, initialMemoryLimit)
        if err != nil {
            log.Printf("âŒ Erro ao ajustar contÃªiner: %v", err)
        }

        time.Sleep(5 * time.Second)
    }
}
